Source: https://developers.meta.com/horizon-worlds/learn/documentation/desktop-editor/generative-ai-creation-tools/generative-ai-creation-code-tool

# Generative AI Assistant Tool

Important

 Join the [Meta Horizon Creator Program](https://developers.meta.com/horizon-worlds/programs)! As a member, you gain:

* Access to monetization opportunities including monthly bonuses, in-world purchases and competition cash prizes.
* Helpful resources including educational content, technical support and a collaborative creator community.

Important

 To report bugs, go to the main menu and select **Report a problem**. To give us feedback, select **Help us improve** from the main menu.

When creating a world in Horizon, using Typescript can be a challenge. The Generative AI Assistant Tool can help you learn Typescript by generating code snippets, and even take actions to help accelerate your world building process. The tool is available in the Horizon Desktop Editor and it is an authoritative, AI-powered chat assistant. The tool works like a chat app and is as simple as having a back-and-forth, real-time conversation with someone. In this case, that someone just happens to be an [LLM](https://en.wikipedia.org/wiki/Large_language_model).

Keep in mind there are daily rate limits for using the Generative AI Assistant Tool. You can check the rates limits in in the following section.

Gen AI Tool Availability & Rates

 Access to GenAI features is automated and determined based on your location when using the Desktop Editor. If you move from an unsupported location to a supported location or vice versa, there will be a delay in updating your access for GenAI features. Horizon desktop editor’s GenAI tools are currently available to users aged 13+ and the Creator Assistant tool is available to users aged 18+. Access to GenAI features is automated and determined based on your location when using the desktop editor. If you move from an unsupported location to a supported location or vice versa, there will be a delay in updating your access for GenAI Features. The GenAI features are available in the following regions: United States, the United Kingdom (UK), Canada, India, Australia, France, Germany, Spain, Brazil, the Netherlands, Italy, Poland, Argentina, Vietnam, Mexico, New Zealand, Sweden, Belgium, Ireland, Switzerland, Denmark, Finland, Norway, Singapore, Iceland, and Austria. Additionally there are daily rate limits per user on content created using Meta AI. These limits are:

* Typescript - 1000 requests
* Audio SFX/Ambient - 200 requests
* Skybox Generation - 50 requests
* Mesh Generation - 100 requests

To access the Generative AI Assistant Tool, select **Gen AI** from the top menu bar. You can then select the **Assistant** tool to enable the Horizon Generative AI Assistant.

<details>
<summary>Gen AI Assistant Icon</summary>

<p></p>

[Gen AI Assistant Icon](../../../../images/output/img_20251211_031330_20251211_031330.md)

### Overview
This image depicts a user interface element, specifically a dropdown menu or a contextual menu, with a focus on an "Assistant" option. The menu is partially open, revealing a description underneath the selected item.

### Key Elements
- **Visual description**: The menu has a rectangular shape with rounded corners.
- **Location**: Positioned at the top-left corner of the interface.
- **Contents**: Contains the word "Assistant" in white text on a dark blue background.
- **Visual styling**: The background is dark blue (#005785), and the text is white (#FFFFFF).

- **Visual description**: Below the "Assistant" option, there is a description area outlined in blue.
- **Location**: Directly beneath the "Assistant" option.
- **Contents**: The description reads: "Prompt to generate assets, create code, execute complex tasks, brainstorm, and more."
- **Visual styling**: The background of the description area is black (#000000), and the text is light gray (#CCCCCC).

- **Visual description**: A "Generate" button is located below the description area.
- **Location**: Positioned centrally below the description area.
- **Contents**: The button has a dark blue background with white text that says "Generate."
- **Visual styling**: The button has a dark blue background (#005785) and white text (#FFFFFF).

- **Visual description**: To the right of the "Generate" button, there is a small icon and a downward arrow.
- **Location**: Positioned to the right of the "Generate" button.
- **Contents**: The icon resembles a plus sign within a square, and the arrow points downward.
- **Visual styling**: The icon is white (#FFFFFF) with a dark blue background (#005785).

### Visual Flow / Relationships
- **Most prominent visually**: The "Assistant" option is the most prominent due to its larger size and distinct color.
- **Arrows/lines/connectors**: There are no arrows, lines, or connectors visible in the image.
- **Spatial relationships**: The elements are arranged in a linear fashion from left to right: "Assistant" -> Description -> "Generate" -> Icon + Arrow.

</details>

<p></p>



## Use the Generative AI Assistant Tool

The Generative AI Assistant Tool can take action in your world handle basic end-to-end processes during the world building process. You can enable this mode by selecting **Code and act** as the mode for the assistant.

As an example, by entering the prompt “Make a door that opens when a button is pressed”, the Generative AI Assistant Tool can take the following actions:

* Find assets in the **Asset Library** and place them in your world
* Modify entity properties
* Create scripts and connect them to your world
* Instruct you on additional steps needed to adjust editor settings

You can also regenerate the content by re-submitting your prompt until you get a satisfactory response.

To use the Generative AI Assistant tool, use the following process:

- Select **Gen AI** from the top menu bar, then select the **Assistant** and set the mode to **Code and act**.
  <details>
<summary>Code and act menu option</summary>

<p></p>

[Code and act menu option](../../../../images/output/img_20251211_031429_20251211_031429.md)

### Overview
This image depicts a dropdown menu with two options: "Code and act" and "Code only." The menu is part of a user interface, likely within a software application related to game development or scripting.

### Key Elements
- **"Code and act" Option**: Located at the top of the dropdown menu. It has a checkmark next to it, indicating it is the currently selected option. The text reads: "The assistant will set up complete gameplay systems by generating scripts, finding and spawning assets, and attaching scripts to objects."
- **"Code only" Option**: Located below the "Code and act" option. The text reads: "The assistant will only generate typescript code snippets."
- **Dropdown Menu Background**: Dark gray with a subtle gradient effect.
- **Menu Border**: Thin white border around the menu.
- **Menu Items**: Text is white, providing contrast against the dark background.
- **Menu Position**: The dropdown menu is partially overlaid on another part of the interface, suggesting it is triggered by a button or icon just outside the frame.

### Visual Flow / Relationships
- **Most Prominent Element**: The "Code and act" option due to its checkmark and placement at the top.
- **Arrows/Connectors**: None visible.
- **Reading Order**: The options are read from top to bottom.
- **Spatial Relationships**: The "Code and act" option is above "Code only," and both are contained within the same dropdown menu.

</details>

<p></p>


- Input a prompt into the prompt window. This can be a natural language prompt that’s more conversational like “Create a platform that floats when I step on it.”
- Click **Generate** and the Gen AI Assistant will begin executing on your task. The Assistant will narrate its actions so you can follow along with its process and check its steps.
  <details>
<summary>Gen AI Assistant process</summary>

<p></p>

[Gen AI Assistant process](../../../../images/output/img_20251211_031538_20251211_031538.md)

### Overview
This image depicts a chat interface within a digital application, likely a design or development tool. The interface includes a message input field at the top, followed by a conversation thread with messages exchanged between users.

### Key Elements
- **Message Input Field**: Located at the top, it has a blue background with white text that reads: "Create a platform that floats when I step on it." It features a white circular loading indicator on the left side.
- **User Message**: Below the input field, there is a dark gray message bubble containing white text stating: "Of course! I can create a platform that floats up when you step on it."
- **System Message**: Another dark gray message bubble follows, containing white text that says: "First, I'll look for a suitable platform asset for you."
- **Asset Search Result**: A light gray message bubble with a small icon resembling a 3D cube with a plus sign appears next, indicating no assets were found. The text reads: "Found 0 assets."
- **Follow-Up Message**: The final message is another dark gray bubble with white text saying: "That last result wasn't quite right. Let me try searching for a better platform asset for you."

### Visual Flow / Relationships
The visual hierarchy is clear, with the user's input at the top, followed by the system's responses. The conversation flows downward, with the system messages appearing below the user's input. The loading indicator suggests that the system is processing the user's request.

</details>

<p></p>


- Once the process completes, the Assistant will validate its output and then indicate that the process is complete. Any new assets created will appear in the **Hierarchy** pane on the left side.
- Once the process is complete, you can converse with the Gen AI Assistant to make updates to the created content, or other parts of your world.
  <details>
<summary>Gen AI successful validation</summary>

<p></p>

[Gen AI successful validation](../../../../images/output/img_20251211_031627_20251211_031627.md)

### Overview
This image depicts a chat interface with two messages displayed against a dark background. The messages are presented in rounded rectangular bubbles with a subtle shadow effect, giving them a three-dimensional appearance. The content of the messages is clearly legible and formatted as text.

### Key Elements
1. **Message Bubble 1**
   - **Visual description**: A rounded rectangular bubble with a dark gray background and a lighter gray border.
   - **Location**: Top portion of the image.
   - **Contents**: Contains the text "> Validation was successful. Output is valid." in white font.
   - **Visual styling**: The text is centered within the bubble, and there are no additional elements inside the bubble.

2. **Message Bubble 2**
   - **Visual description**: A rounded rectangular bubble with a dark gray background and a lighter gray border.
   - **Location**: Below the first message bubble.
   - **Contents**: Contains the text "> Perfect! The floating platform is now set up and working correctly. When you step on it, it will rise into the air. Let me know if you need anything else!" in white font.
   - **Visual styling**: The text is also centered within the bubble, and there are no additional elements inside the bubble.

### Visual Flow / Relationships
The visual hierarchy is clear due to the placement of the messages. The first message is slightly smaller and positioned above the second larger message. There are no arrows or lines connecting the messages, but the layout suggests a chronological sequence of communication.

</details>

<p></p>



Currently the Gen AI Assistant is only capable of tasks focused on **basic interactivity** and **basic system prompts**. It cannot autonomously complete complex workflows and is limited to mechanics that Typescript can interact with. Additionally it cannot interact with any of the additional generators in the **Gen AI** panel.

The following are examples of use cases that the Gen AI Assistant can do and can help as a framework for interacting with the Gen AI Assistant:

* As a builder, I can ask a “how do I” question and retrieve up to date results from Horizon documentation to answer my question:
  + How do I **interact with Unity Asset Bundles**?
  + How do I **create my own custom asset**?
  + How do I **work with animations in Horizon**?
  + How do I **learn Typescript**?
  + How do I **implement a Custom UI system in Horizon**?
* As a builder, I can ask the AI Assistant to implement basic interactivity / basic systems:
  + Build a **floor tile that activates when stepped on**.
  + Create a **lever that can be switched on and off**.
  + Generate **coins that players can collect for points**.
  + Design a **door that requires a key to open**.
  + Make **health packs that heal players when picked up**.
  + Construct a **pad that teleports players to another location**.
  + Develop a **platform that moves back and forth**.
  + Engineer an **elevator that goes up and down**.
  + Build a **device that launches players into the air**.
  + Design a **spinning obstacle that hurts players**.
  + Create **platforms that fall or disappear when stepped on**.
  + Establish an **area that makes players run faster**.
  + Construct a **floor that damages players like lava**.
  + Generate a **gun that shoots projectiles**.
  + Make **targets that can be shot at**.
  + Create **barrels that explode when hit**.
  + Implement a **countdown timer for my game**.
  + Design a **door that opens when players get close**.
  + Build a **puzzle with pressure plates that need specific weights**.
  + Create a **combination lock puzzle**.
  + Generate a **box that spawns random items**.
  + Implement a **randomizer like rolling dice**.
  + Design a **system that spawns objects repeatedly**.
  + Construct a **dance floor with music**.

## Generating TypeScript code snippets

**Note**: The Generative AI Creation Tool can only generate code using [version 2 of the Meta Horizon Worlds Typescript API](../../Scripting/API%20references%20and%20examples/Horizon%20TypeScript%20V2%20Changes.md).

The Generative AI Assistant tool can also generate Typescript snippets for you to attach to objects in your world. For best results when generating Typescript APIs, try to keep your scope limited to one API at a time.

Responses will occasionally contain [hallucinations](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)). This usually happens when there are no supported APIs available for the given prompt.

If a response doesn’t give the expected result, try reframing your prompt to be more clear and specific.

To generate code snippets using the Gen AI Assistant, use the following process:

- Select the **Assistant** icon and set the **Mode** to **Code Only**.

  <details>
<summary>Gen AI typescript option</summary>

<p></p>

[Gen AI typescript option](../../../../images/output/img_20251211_031722_20251211_031722.md)

### Overview
This image depicts a user interface element showing two options within a dropdown menu. The main content area explains the functionality of the assistant under the "Code and act" option, while the dropdown menu below offers a choice between "Code only" and "Code and act."

### Key Elements
- **Main Content Area**: Located at the top, this area has a dark background with white text explaining the assistant's capabilities. It states: 
    > The assistant will set up complete gameplay systems by generating scripts, finding and spawning assets, and attaching scripts to objects.
- **Dropdown Menu**: Positioned below the main content area, this menu has a lighter gray background compared to the main content area. It contains two options:
    - **"Code only"**: This option is currently selected, indicated by a downward arrow next to the text. The text reads:
        > The assistant will only generate typescript code snippets.
    - **"Code and act"**: This option is not selected, as indicated by the absence of an arrow next to it. The text reads:
        > The assistant will set up complete gameplay systems by generating scripts, finding and spawning assets, and attaching scripts to objects.

### Visual Flow / Relationships
The most prominent visual element is the main content area, which provides an overview of the assistant's capabilities. The dropdown menu is secondary but important for selecting specific modes of operation. There are no arrows or lines connecting elements, so the relationship is purely hierarchical, with the main content area being more prominent than the dropdown menu.

</details>

<p></p>


- Select either the LLama or Specialist model with the **Model** dropdown.
- Enter a prompt into the prompt window and click **Generate**.
- The Gen AI Assistant will create a sample snippet of Typescript code and provide details on how to use it.
  **Note**: Because this feature is code only, you will still have to follow the steps provided to use the generated typescript snippet

If you would like to change topics, you must start a new conversation by clicking the **New Chat** button.
<details>
<summary>New chat icon</summary>

<p></p>

[New chat icon](../../../../images/output/img_20251211_031819_20251211_031819.md)

### Overview
This image depicts a user interface element, specifically a chat interface with a "New Chat" button. The interface includes a "Gen AI BETA" label at the top, indicating a beta version of a generative artificial intelligence feature. Below the label, there are two icons: one resembling a menu or settings icon, and another that looks like a chat or message icon.

### Key Elements
- **Top Label**: Located at the top-left corner, the label reads "**Gen AI BETA**". The word "BETA" is enclosed in a green rounded rectangle.
- **Menu Icon**: Positioned to the left of the label, it is a gray square with a white icon resembling a menu or settings symbol.
- **Chat Icon**: To the right of the menu icon, there is a gray square with a white icon that looks like a chat bubble with a plus sign, suggesting the addition of a new chat.
- **New Chat Button**: A black rectangular button below the icons, labeled "**New Chat**" in white text.

### Visual Flow / Relationships
The most prominent visual element is the "New Chat" button, as it is centrally located and larger than the other elements. The icons are arranged horizontally above the "New Chat" button, with the menu icon on the left and the chat icon on the right. There are no arrows or lines connecting the elements, but the arrangement suggests a sequential flow from the menu to the chat action.

</details>

<p></p>



Specify whether the result was helpful by clicking either **Like** (thumbs-up), or **Dislike** (thumbs-down). Meta uses this information to fine-tune the LLM.

## View Generative AI tool history

After using the Generative AI Assistant tool, you can view previous chats by selecting the **History** icon.

<details>
<summary>Gen AI History pop</summary>

<p></p>

[Gen AI History pop](../../../../images/output/img_20251211_031909_20251211_031909.md)

### Overview
This image depicts a user interface element, specifically a notification or alert box, likely within a software application. The box contains text and icons, and is part of a larger interface that includes a sidebar with icons and a navigation bar at the top.

### Key Elements
- **Header**: Located at the top-left corner, it reads "Gen AI BETA". The word "BETA" is enclosed in a green oval.
- **Close Button**: Positioned at the top-right corner, it is a white 'X'.
- **Sidebar Icons**: Below the header, there are two icons: one resembling a list (three horizontal lines) and another resembling a pen (indicating edit or write functionality).
- **Notification Box**: A black rectangular box below the sidebar icons contains the text "TODAY" followed by a checkmark and the phrase "Entity Positioning on World Start".

### Visual Flow / Relationships
The most prominent visual element is the notification box, which draws attention due to its contrasting color against the darker background. The header and sidebar icons provide contextual information about the application's features. The checkmark next to the text indicates a completed action or confirmation.

</details>

<p></p>



After opening the history window you can select a previous conversation. This will restore the selected conversation including the context used to generate content.

## What’s next?

To learn more about Meta Horizon Worlds, try the following:

- [Create your first world](../../Get%20started/Create%20your%20first%20world%20tutorial,%20part%201.md) using our step-by-step tutorial.
- If you have issues when running the desktop editor, see [Desktop Editor Troubleshooting](../Help%20and%20reference/Desktop%20editor%20troubleshooting.md)
- Learn about the desktop editor with the [Introduction to the Desktop Editor](../Get%20started%20with%20Desktop%20Editor/Introduction%20to%20the%20desktop%20editor.md).
- Learn about the other tools available by reading our [Tools Overview](../../Get%20started/Tools%20overview.md).
- Join the [Meta Horizon Creator Program](https://developers.meta.com/horizon-worlds/programs/) to learn about our program benefits.